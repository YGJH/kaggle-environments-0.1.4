#!/usr/bin/env python3
"""
æª¢æŸ¥æ¨¡å‹å¤§å°å’Œé ä¼° submission.py æ–‡ä»¶å¤§å°
"""
import torch
import numpy as np
import os
import base64

def check_model_size():
    """æª¢æŸ¥æ¨¡å‹å¤§å°å’Œåƒæ•¸æ•¸é‡"""
    print("ğŸ” æª¢æŸ¥æ¨¡å‹å¤§å°å’Œåƒæ•¸")
    print("=" * 50)
    
    # æª¢æŸ¥æ˜¯å¦æœ‰æ¨¡å‹æ–‡ä»¶
    checkpoint_files = []
    if os.path.exists("checkpoints"):
        for file in os.listdir("checkpoints"):
            if file.endswith(".pt"):
                checkpoint_files.append(file)
    
    if not checkpoint_files:
        print("âŒ æ²’æœ‰æ‰¾åˆ°ä»»ä½• .pt æ¨¡å‹æ–‡ä»¶")
        return
    
    # ä½¿ç”¨æœ€æ–°çš„æœ€ä½³æ¨¡å‹
    best_models = [f for f in checkpoint_files if f.startswith('best_model')]
    if best_models:
        model_file = sorted(best_models)[-1]
    else:
        model_file = sorted(checkpoint_files)[-1]
    
    model_path = f"checkpoints/{model_file}"
    print(f"ğŸ“ æª¢æŸ¥æ¨¡å‹: {model_path}")
    
    # æª¢æŸ¥æ–‡ä»¶å¤§å°
    file_size = os.path.getsize(model_path)
    print(f"ğŸ“Š æ¨¡å‹æ–‡ä»¶å¤§å°: {file_size / 1024 / 1024:.2f} MB")
    
    # è¼‰å…¥æ¨¡å‹
    try:
        checkpoint = torch.load(model_path, map_location="cpu")
        state_dict = checkpoint['model_state_dict']
        
        # è¨ˆç®—åƒæ•¸æ•¸é‡
        total_params = 0
        for name, param in state_dict.items():
            param_count = param.numel()
            total_params += param_count
            print(f"  {name}: {param.shape} -> {param_count:,} åƒæ•¸")
        
        print(f"\nğŸ“ˆ ç¸½åƒæ•¸æ•¸é‡: {total_params:,}")
        print(f"ğŸ“ˆ ä¼°è¨ˆæ¨¡å‹å¤§å°: {total_params * 4 / 1024 / 1024:.2f} MB (float32)")
        
        # æ¸¬è©¦ numpy å£“ç¸®æ•ˆæœ
        print(f"\nğŸ—œï¸ æ¸¬è©¦å£“ç¸®æ•ˆæœ:")
        
        # è½‰æ›ç‚º numpy ä¸¦ä¿å­˜ç‚º .npz
        temp_file = "temp_weights.npz"
        np.savez_compressed(temp_file, **{k: v.numpy() for k, v in state_dict.items()})
        
        npz_size = os.path.getsize(temp_file)
        print(f"  .npz å£“ç¸®å¾Œ: {npz_size / 1024 / 1024:.2f} MB")
        
        # æ¸¬è©¦ Base64 ç·¨ç¢¼å¤§å°
        with open(temp_file, "rb") as f:
            weights_bytes = f.read()
            weights_b64 = base64.b64encode(weights_bytes).decode('utf-8')
        
        b64_size = len(weights_b64)
        print(f"  Base64 ç·¨ç¢¼: {b64_size / 1024 / 1024:.2f} MB")
        
        # ä¼°è¨ˆæœ€çµ‚ submission.py å¤§å°
        # Base64 å­—ç¬¦ä¸² + Python ä»£ç¢¼
        code_overhead = 5000  # ä¼°è¨ˆ Python ä»£ç¢¼å¤§å°
        estimated_submission_size = b64_size + code_overhead
        
        print(f"\nğŸ“‹ é ä¼° submission.py å¤§å°:")
        print(f"  Base64 æ¬Šé‡: {b64_size / 1024 / 1024:.2f} MB")
        print(f"  Python ä»£ç¢¼: {code_overhead / 1024:.2f} KB")
        print(f"  ç¸½å¤§å°: {estimated_submission_size / 1024 / 1024:.2f} MB")
        
        # æª¢æŸ¥æ˜¯å¦è¶…éé™åˆ¶
        size_limit_mb = 100
        if estimated_submission_size / 1024 / 1024 > size_limit_mb:
            print(f"\nâš ï¸ è­¦å‘Š: é ä¼°å¤§å° ({estimated_submission_size / 1024 / 1024:.2f} MB) è¶…é {size_limit_mb} MB é™åˆ¶ï¼")
            
            # å»ºè­°å„ªåŒ–æ–¹æ¡ˆ
            print(f"\nğŸ’¡ å„ªåŒ–å»ºè­°:")
            print(f"  1. æ¸›å°‘éš±è—å±¤å¤§å° (ç•¶å‰: 512)")
            print(f"  2. æ¸›å°‘æ®˜å·®å¡Šæ•¸é‡ (ç•¶å‰: 6)")
            print(f"  3. ä½¿ç”¨ float16 ç²¾åº¦")
            print(f"  4. é€²è¡Œæ¨¡å‹å‰ªæ")
            
            # è¨ˆç®—å»ºè­°çš„åƒæ•¸å¤§å°
            target_size_mb = 80  # ç•™ä¸€äº›ç·©è¡
            target_params = int(target_size_mb * 1024 * 1024 / 4)  # å‡è¨­ float32
            print(f"\nğŸ¯ å»ºè­°åƒæ•¸æ•¸é‡: < {target_params:,} (ç•¶å‰: {total_params:,})")
            
        else:
            print(f"\nâœ… æ¨¡å‹å¤§å°åœ¨é™åˆ¶ç¯„åœå…§ (< {size_limit_mb} MB)")
        
        # æ¸…ç†è‡¨æ™‚æ–‡ä»¶
        if os.path.exists(temp_file):
            os.remove(temp_file)
            
    except Exception as e:
        print(f"âŒ è¼‰å…¥æ¨¡å‹å¤±æ•—: {e}")

def check_config_impact():
    """æª¢æŸ¥é…ç½®å°æ¨¡å‹å¤§å°çš„å½±éŸ¿"""
    print(f"\nğŸ”§ ç•¶å‰é…ç½®åˆ†æ:")
    print("=" * 30)
    
    try:
        import yaml
        with open('config.yaml', 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        
        agent_config = config.get('agent', {})
        
        input_size = agent_config.get('input_size', 126)
        hidden_size = agent_config.get('hidden_size', 512)
        num_layers = agent_config.get('num_layers', 4)
        
        print(f"  è¼¸å…¥å¤§å°: {input_size}")
        print(f"  éš±è—å±¤å¤§å°: {hidden_size}")
        print(f"  éš±è—å±¤æ•¸é‡: {num_layers}")
        
        # è¨ˆç®—é æœŸåƒæ•¸æ•¸é‡
        # è¼¸å…¥å±¤: input_size * hidden_size + hidden_size
        input_params = input_size * hidden_size + hidden_size
        
        # æ¯å€‹æ®˜å·®å¡Š: 2 * (hidden_size * hidden_size + hidden_size)
        residual_params = num_layers * 2 * (hidden_size * hidden_size + hidden_size)
        
        # ç­–ç•¥é ­: hidden_size * (hidden_size // 2) + (hidden_size // 2) + (hidden_size // 2) * 7 + 7
        policy_params = hidden_size * (hidden_size // 2) + (hidden_size // 2) + (hidden_size // 2) * 7 + 7
        
        # åƒ¹å€¼é ­: hidden_size * (hidden_size // 2) + (hidden_size // 2) + (hidden_size // 2) * 1 + 1
        value_params = hidden_size * (hidden_size // 2) + (hidden_size // 2) + (hidden_size // 2) * 1 + 1
        
        total_estimated = input_params + residual_params + policy_params + value_params
        
        print(f"\nğŸ“Š é ä¼°åƒæ•¸åˆ†å¸ƒ:")
        print(f"  è¼¸å…¥å±¤: {input_params:,}")
        print(f"  æ®˜å·®å¡Š: {residual_params:,}")
        print(f"  ç­–ç•¥é ­: {policy_params:,}")
        print(f"  åƒ¹å€¼é ­: {value_params:,}")
        print(f"  ç¸½è¨ˆ: {total_estimated:,}")
        print(f"  ä¼°è¨ˆå¤§å°: {total_estimated * 4 / 1024 / 1024:.2f} MB")
        
    except Exception as e:
        print(f"âŒ ç„¡æ³•è®€å–é…ç½®: {e}")

if __name__ == "__main__":
    check_model_size()
    check_config_impact()
