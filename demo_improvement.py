#!/usr/bin/env python3
"""
æ¼”ç¤ºæ–°èˆŠæ¨¡ä»¿å­¸ç¿’ç³»çµ±çš„å·®ç•°
"""

from c4solver_wrapper import C4SolverWrapper
from imitation_learning import ImitationDataset  # èˆŠç³»çµ±
from perfect_imitation_learning import PerfectExpertPolicy  # æ–°ç³»çµ±
import numpy as np

def demonstrate_policy_difference():
    """æ¼”ç¤ºç­–ç•¥å·®ç•°"""
    print("ğŸ” æ–°èˆŠæ¨¡ä»¿å­¸ç¿’ç³»çµ±ç­–ç•¥å°æ¯”")
    print("="*60)
    
    solver = C4SolverWrapper('connect4/c4solver')
    
    # æ¸¬è©¦å¹¾å€‹é—œéµå±€é¢
    test_cases = [
        ([0] * 42, "ç©ºå±€é¢"),
        # ä¸­å¤®é–‹å±€
        ([0]*35 + [1, 0, 0, 0, 0, 0, 0], "ä¸­å¤®é–‹å±€"),
    ]
    
    old_dataset = ImitationDataset(solver)
    new_expert = PerfectExpertPolicy(solver)
    
    for board, description in test_cases:
        print(f"\nğŸ“‹ æ¸¬è©¦å±€é¢: {description}")
        
        valid_actions = [c for c in range(7) if board[c] == 0]
        
        # C4SolveråŸå§‹çµæœ
        c4solver_result = solver.solve_position('', analyze=True) if description == "ç©ºå±€é¢" else None
        if c4solver_result:
            print(f"C4SolveråŸå§‹åˆ†æ•¸: {c4solver_result['scores']}")
            print(f"C4Solveræœ€ä½³å‹•ä½œ: {np.argmax(c4solver_result['scores'])}")
        
        # èˆŠç³»çµ± (éŒ¯èª¤çš„softmax)
        old_policy = old_dataset.get_expert_action_distribution(board, 1)
        print(f"èˆŠç³»çµ±ç­–ç•¥åˆ†ä½ˆ: {old_policy}")
        print(f"èˆŠç³»çµ±æœ€ä½³å‹•ä½œ: {np.argmax(old_policy)}")
        print(f"èˆŠç³»çµ±æœ€å¤§æ¦‚ç‡: {np.max(old_policy):.3f}")
        
        # æ–°ç³»çµ± (æ­£ç¢ºçš„one-hot)
        new_policy = new_expert.get_expert_policy(board, valid_actions)
        print(f"æ–°ç³»çµ±ç­–ç•¥åˆ†ä½ˆ: {new_policy}")
        print(f"æ–°ç³»çµ±æœ€ä½³å‹•ä½œ: {np.argmax(new_policy)}")
        print(f"æ–°ç³»çµ±æœ€å¤§æ¦‚ç‡: {np.max(new_policy):.3f}")
        
        # åˆ†æå·®ç•°
        print(f"\nğŸ” é—œéµå·®ç•°:")
        old_best = np.argmax(old_policy)
        new_best = np.argmax(new_policy)
        print(f"  å‹•ä½œä¸€è‡´æ€§: {'âœ…' if old_best == new_best else 'âŒ'}")
        print(f"  ç­–ç•¥ç²¾ç¢ºæ€§: èˆŠ={np.max(old_policy):.3f} vs æ–°={np.max(new_policy):.3f}")
        
        # è¨ˆç®—ç­–ç•¥ç†µ (ç†µè¶Šä½è¶Šç²¾ç¢º)
        old_entropy = -np.sum(old_policy * np.log(old_policy + 1e-8))
        new_entropy = -np.sum(new_policy * np.log(new_policy + 1e-8))
        print(f"  ç­–ç•¥ç†µå€¼: èˆŠ={old_entropy:.3f} vs æ–°={new_entropy:.3f} (è¶Šä½è¶Šå¥½)")
        
        print("-" * 60)

def analyze_training_implications():
    """åˆ†æè¨“ç·´å½±éŸ¿"""
    print("\nğŸ¯ è¨“ç·´å½±éŸ¿åˆ†æ")
    print("="*60)
    
    print("èˆŠç³»çµ±å•é¡Œ:")
    print("âŒ softmaxæ‰­æ›²äº†C4Solverçš„çœŸå¯¦ç­–ç•¥")
    print("âŒ æ¨¡å‹å­¸åˆ°æ¨¡ç³Šçš„æ¦‚ç‡åˆ†ä½ˆï¼Œä¸æ˜¯ç²¾ç¢ºæ±ºç­–")
    print("âŒ è¨“ç·´æ”¶æ–‚ä½†ä¸æ˜¯æ”¶æ–‚åˆ°æ­£ç¢ºçš„ç­–ç•¥")
    print("âŒ é æœŸæº–ç¢ºç‡: 60-70%")
    
    print("\næ–°ç³»çµ±å„ªå‹¢:")
    print("âœ… ç›´æ¥è¤‡è£½C4Solverçš„æœ€å„ªæ±ºç­–")
    print("âœ… æ¨¡å‹å­¸åˆ°ç²¾ç¢ºçš„one-hotç­–ç•¥")
    print("âœ… è¨“ç·´æ”¶æ–‚åˆ°å®Œç¾çš„å°ˆå®¶ç­–ç•¥")
    print("âœ… é æœŸæº–ç¢ºç‡: 95%+")
    
    print("\nğŸš€ RLè¨“ç·´æ”¹é€²:")
    print("ğŸ”¥ åˆå§‹å‹ç‡: å¾10% â†’ 80%+")
    print("ğŸ”¥ æ”¶æ–‚é€Ÿåº¦: å¿«5-10å€")
    print("ğŸ”¥ æœ€çµ‚æ€§èƒ½: æ¥è¿‘C4Solveræ°´å¹³")

if __name__ == "__main__":
    try:
        demonstrate_policy_difference()
        analyze_training_implications()
        
        print("\nğŸ‰ çµè«–:")
        print("æ–°çš„å®Œç¾æ¨¡ä»¿å­¸ç¿’ç³»çµ±ä¿®å¾©äº†è‡´å‘½çš„ç­–ç•¥è¡¨ç¤ºå•é¡Œï¼Œ")
        print("ç¢ºä¿æ¨¡å‹100%å­¸æœƒC4Solverçš„å®Œæ•´ç­–ç•¥ï¼")
        
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºå¤±æ•—: {e}")
        print("è«‹ç¢ºä¿C4Solverå¯ç”¨ä¸”ä¾è³´å·²å®‰è£")
