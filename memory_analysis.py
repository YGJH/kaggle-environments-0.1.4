#!/usr/bin/env python3
"""
è¨˜æ†¶é«”ä½¿ç”¨åˆ†æè…³æœ¬
åˆ†æä¸åŒè¼‰å…¥æ–¹å¼çš„ç†è«–è¨˜æ†¶é«”ä½¿ç”¨æƒ…æ³
"""

import os
import sys
import numpy as np
import time
from datetime import datetime

def analyze_file_size(file_path):
    """åˆ†ææ–‡ä»¶å¤§å°"""
    if not os.path.exists(file_path):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        return None
    
    file_size = os.path.getsize(file_path)
    file_size_mb = file_size / 1024 / 1024
    
    print(f"ğŸ“ æ–‡ä»¶åˆ†æ: {file_path}")
    print(f"   æ–‡ä»¶å¤§å°: {file_size_mb:.1f} MB ({file_size:,} bytes)")
    
    # ä¼°ç®—è¡Œæ•¸
    with open(file_path, 'r') as f:
        first_line = f.readline()
        line_length = len(first_line)
    
    estimated_lines = file_size // line_length if line_length > 0 else 0
    print(f"   ä¼°ç®—è¡Œæ•¸: {estimated_lines:,}")
    print(f"   å¹³å‡è¡Œé•·: {line_length} å­—ç¬¦")
    
    return {
        'file_size_mb': file_size_mb,
        'estimated_lines': estimated_lines,
        'line_length': line_length
    }

def calculate_memory_usage(num_samples):
    """è¨ˆç®—ç†è«–è¨˜æ†¶é«”ä½¿ç”¨æƒ…æ³"""
    # æ¯å€‹æ¨£æœ¬çš„æ•¸æ“šçµæ§‹å¤§å°
    state_size = 126 * 4  # 126å€‹float32ï¼Œæ¯å€‹4å­—ç¯€
    action_values_size = 7 * 4  # 7å€‹float32ï¼Œæ¯å€‹4å­—ç¯€
    
    sample_size = state_size + action_values_size  # æ¯å€‹æ¨£æœ¬çš„ç¸½å¤§å°
    
    # åŸå§‹æ–¹å¼çš„è¨˜æ†¶é«”ä½¿ç”¨ï¼ˆé‡è¤‡å„²å­˜ï¼‰
    original_memory = (
        num_samples * 50 +  # åŸå§‹æ–‡æœ¬è¡Œï¼ˆå¹³å‡50å­—ç¬¦perè¡Œï¼‰
        num_samples * sample_size * 2 +  # Pythonåˆ—è¡¨å„²å­˜ï¼ˆæœ‰overheadï¼‰
        num_samples * sample_size  # numpyæ•¸çµ„
    ) / 1024 / 1024  # è½‰æ›ç‚ºMB
    
    # å„ªåŒ–æ–¹å¼çš„è¨˜æ†¶é«”ä½¿ç”¨ï¼ˆé åˆ†é…ï¼‰
    optimized_memory = (
        num_samples * sample_size  # ç›´æ¥numpyæ•¸çµ„
    ) / 1024 / 1024  # è½‰æ›ç‚ºMB
    
    return {
        'original': original_memory,
        'optimized': optimized_memory,
        'saved': original_memory - optimized_memory,
        'ratio': original_memory / optimized_memory if optimized_memory > 0 else 1
    }

def analyze_memory_expansion():
    """åˆ†æè¨˜æ†¶é«”è†¨è„¹åŸå› """
    print(f"\nğŸ” è¨˜æ†¶é«”è†¨è„¹åŸå› åˆ†æ")
    print("=" * 50)
    
    print("åŸå§‹æ•¸æ“šæ ¼å¼:")
    print("  - æ–‡æœ¬æ–‡ä»¶: æ¯è¡Œç´„50å€‹å­—ç¬¦ (ASCII)")
    print("  - å„²å­˜å¤§å°: 50 bytes per sample")
    
    print("\nè¼‰å…¥å¾Œæ•¸æ“šæ ¼å¼:")
    print("  - ç‹€æ…‹ç·¨ç¢¼: 126å€‹float32 = 126 Ã— 4 = 504 bytes")
    print("  - å‹•ä½œåƒ¹å€¼: 7å€‹float32 = 7 Ã— 4 = 28 bytes")
    print("  - ç¸½è¨ˆ: 532 bytes per sample")
    
    print(f"\nè†¨è„¹æ¯”ä¾‹: 532 / 50 = {532/50:.1f}x")
    
    print("\nåŸå§‹è¼‰å…¥æ–¹å¼çš„å•é¡Œ:")
    print("  1. ğŸ”„ é‡è¤‡å„²å­˜:")
    print("     - åŸå§‹æ–‡æœ¬è¡Œ")
    print("     - Pythonåˆ—è¡¨ (æœ‰é¡å¤–overhead)")
    print("     - æœ€çµ‚numpyæ•¸çµ„")
    print("  2. ğŸ“ˆ å‹•æ…‹æ“´å±•:")
    print("     - list.append()æœƒé åˆ†é…é¡å¤–ç©ºé–“")
    print("     - é€ æˆè¨˜æ†¶é«”ç¢ç‰‡")
    print("  3. ğŸ”€ æ•¸æ“šé¡å‹è½‰æ›:")
    print("     - å­—ç¬¦ä¸² â†’ æ•¸å­— â†’ numpyæ•¸çµ„")
    print("     - å¤šæ¬¡é¡å‹è½‰æ›å’Œè¤‡è£½")

def main():
    """ä¸»åˆ†æå‡½æ•¸"""
    print("ğŸ” ConnectX è¨˜æ†¶é«”ä½¿ç”¨åˆ†æ")
    print("=" * 60)
    
    dataset_file = "connectx-state-action-value.txt"
    
    # åˆ†ææ–‡ä»¶
    file_info = analyze_file_size(dataset_file)
    if file_info is None:
        print("ä½¿ç”¨æ¨¡æ“¬æ•¸æ“šé€²è¡Œåˆ†æ...")
        file_info = {
            'file_size_mb': 7800,  # 7.8GB
            'estimated_lines': 150000000,  # 1.5å„„è¡Œ
            'line_length': 50
        }
    
    # åˆ†æè¨˜æ†¶é«”è†¨è„¹
    analyze_memory_expansion()
    
    # æ¸¬è©¦ä¸åŒæ¨£æœ¬æ•¸é‡
    test_sizes = [1000, 10000, 50000, 100000, 500000]
    
    print(f"\nğŸ“Š è¨˜æ†¶é«”ä½¿ç”¨æ¯”è¼ƒ")
    print(f"{'æ¨£æœ¬æ•¸':<10} {'åŸå§‹æ–¹å¼':<12} {'å„ªåŒ–æ–¹å¼':<12} {'ç¯€çœ':<10} {'è†¨è„¹æ¯”':<8}")
    print("-" * 60)
    
    for test_size in test_sizes:
        memory_info = calculate_memory_usage(test_size)
        
        print(f"{test_size:<10} {memory_info['original']:.1f} MB     {memory_info['optimized']:.1f} MB     {memory_info['saved']:.1f} MB   {memory_info['ratio']:.1f}x")
    
    # ç‰¹åˆ¥åˆ†æå¤§æ•¸æ“šé›†
    full_dataset_samples = min(file_info['estimated_lines'], 1000000)  # é™åˆ¶åˆ°100è¬æ¨£æœ¬
    full_memory_info = calculate_memory_usage(full_dataset_samples)
    
    print(f"\nğŸ¯ å®Œæ•´æ•¸æ“šé›†åˆ†æ ({full_dataset_samples:,} æ¨£æœ¬):")
    print(f"   åŸå§‹æ–¹å¼: {full_memory_info['original']:.1f} MB ({full_memory_info['original']/1024:.1f} GB)")
    print(f"   å„ªåŒ–æ–¹å¼: {full_memory_info['optimized']:.1f} MB ({full_memory_info['optimized']/1024:.1f} GB)")
    print(f"   ç¯€çœè¨˜æ†¶é«”: {full_memory_info['saved']:.1f} MB ({full_memory_info['saved']/1024:.1f} GB)")
    print(f"   æ•ˆç‡æå‡: {full_memory_info['ratio']:.1f}x")
    
    print(f"\nğŸ’¡ å„ªåŒ–æ•ˆæœ:")
    print(f"   âœ… æ¶ˆé™¤é‡è¤‡å„²å­˜ï¼Œè¨˜æ†¶é«”ä½¿ç”¨æ¸›å°‘ {(full_memory_info['ratio']-1)/full_memory_info['ratio']*100:.0f}%")
    print(f"   âœ… é åˆ†é…æ©Ÿåˆ¶é¿å…å‹•æ…‹æ“´å±•é–‹éŠ·")
    print(f"   âœ… æ¸›å°‘è¨˜æ†¶é«”ç¢ç‰‡åŒ–")
    print(f"   âœ… æ”¯æ´åˆ†æ‰¹è¼‰å…¥ï¼Œé©æ‡‰å¤§æ•¸æ“šé›†")
    
    print(f"\nğŸ¯ å»ºè­°:")
    if file_info['file_size_mb'] > 1000:  # å¤§æ–¼1GB
        print(f"   ğŸ“ æ–‡ä»¶è¼ƒå¤§ ({file_info['file_size_mb']:.1f} MB)ï¼Œå¼·çƒˆå»ºè­°ä½¿ç”¨è¨˜æ†¶é«”å„ªåŒ–æ¨¡å¼")
        print(f"   ğŸ’¾ å¯å°‡ max_lines è¨­ç‚º 20000-100000 é€²è¡Œåˆ†æ‰¹è¨“ç·´")
        print(f"   ğŸ”§ åœ¨è¨“ç·´é…ç½®ä¸­è¨­ç½® memory_efficient=True")
    else:
        print(f"   ğŸ“ æ–‡ä»¶é©ä¸­ ({file_info['file_size_mb']:.1f} MB)ï¼Œå¯ä½¿ç”¨æ¨™æº–æ¨¡å¼ä¸€æ¬¡è¼‰å…¥")
        print(f"   âš¡ ä½†å„ªåŒ–æ¨¡å¼ä»ç„¶æ›´æœ‰æ•ˆç‡")

if __name__ == "__main__":
    main()
